## 前置知识

### 黑白灰三色系统

我们以对一个系统的了解程度将系统分为了三类：

- 黑色系统代指黑箱，常见于无监督学习，特征提取
- 白色系统代指纯数学系统，可以完全了解其运作结构
- 灰色系统只能了解其部分结构，不完全知晓其运作机制。

### 混沌理论

> 遵从简单规律的系统会以令人惊讶的复杂方式表现其行为。

美国科学家帕卡德和他的同事基于混沌和[生物进化理论](https://baike.baidu.com/item/生物进化理论/8038751)，借助计算机，致力于用图形来描述金融市场的混沌现象。帕卡德认为，世界上有大量不同的随机现象，他所研究的是大体只需几个变量就能描述系统行为的一种混沌现象。他试图建立一种学习算法，对进化模型进行处理。

## 简介

灰色预测模型的实质是有条件的指数回归模型。它以巧妙的数学推导和令人折服的前瞻性指出任意正有序序列的k次前缀和应具备一定的指数性质，并假定某一前缀和序列中当前点的导数应与该序列值成一线性正比关系。


$$
\frac{d x^{(1)}(t)}{d t}=-\hat{a} x^{(1)}(t)+\hat{b}
$$

上式即为GM(1,1)模型的假定条件。

一个序列必存在一个k，使得它的k阶前缀和具有指数函数性质。这里我们假定该前缀和的导数与前缀和当前点的值具有线性关系。

## 符号说明

我们定义初始非负数据序列为 $x^{(0)}=\left(x^{(0)}(1), x^{(0)}(2), \cdots, x^{(0)}(n)\right)$ ，在此基础上定义其一阶前缀和为 $x^{(1)}(m)=\sum_{i=1}^{m} x^{(0)}(i), m=1,2, \cdots, n$ 。

此外，定义 **紧邻均值生成序列** $z^{(1)}=\left(z^{(1)}(2), z^{(1)}(3), \cdots, z^{(1)}(n)\right)$ ，其中 $z^{(1)}(m)=\delta x^{(1)}(m)+(1-\delta) x^{(1)}(m-1), m=2,3, \cdots, n \text { 且 } \delta=0.5$​​ 。

## 基本形式

GM(1,1)模型的基本形式为：
$$
x^{(0)}(k)+a z^{(1)}(k)=b
$$
本质上是将原序列作为因变量，紧邻均值生成序列作为自变量的线性回归模型。

## 理论推导

由OLS估计（参见线性代数）我们可以得到参数 $a$ 和 $b$​​ 的估计值，这里我们主要将重点放在其意义的阐述上。

由微积分的知识我们知道：
$$
\begin{aligned}
&x^{(0)}(k)=-\hat{a} z^{(1)}(k)+\hat{b} \Rightarrow x^{(1)}(k)-x^{(1)}(k-1)=-\hat{a} z^{(1)}(k)+\hat{b} \\
&x^{(1)}(k)-x^{(1)}(k-1)=\int_{k-1}^{k} \frac{d x^{(1)}(t)}{d t} d t(\text { 牛顿-莱布尼茨公式 }) \\
&z^{(1)}(k)=\frac{x^{(1)}(k)+x^{(1)}(k-1)}{2} \approx \int_{k-1}^{k} x^{(1)}(t) d t(\text { 定积分的几何意义 })
\end{aligned}
$$
由此可得：
$$
\begin{aligned}
\int_{k-1}^{k} \frac{d x^{(1)}(t)}{d t} d t & \approx-\hat{a} \int_{k-1}^{k} x^{(1)}(t) d t+\int_{k-1}^{k} \hat{b} d t \\
&=\int_{k-1}^{k}\left[-\hat{a} x^{(1)}(t)+\hat{b}\right] d t
\end{aligned}
$$
所以上述模型等价于：
$$
\text { 微分方程: } \frac{d x^{(1)}(t)}{d t}=-\hat{a} x^{(1)}(t)+\hat{b}
$$
这就是我们之前提到的假定条件的表现形式。

解微分方程后得：
$$
\hat{x}^{1}(k+1)=\left[x^{0}(1)-\frac{b}{a}\right] \mathrm{e}^{-a k}+\frac{b}{a}
$$

## 代码

```python
import itertools
import numpy as np
import math

from matplotlib import pyplot as plt

a = [560823, 542386, 604834, 591248, 583031, 640636, 575688, 689637, 570790, 519574, 614677]
x0 = [104, 101.8, 105.8, 111.5, 115.97, 120.03, 113.3, 116.4, 105.1, 83.4, 73.3]
x1 = [135.6, 140.2, 140.1, 146.9, 144, 143, 133.3, 135.7, 125.8, 98.5, 99.8]
x2 = [131.6, 135.5, 142.6, 143.2, 142.2, 138.4, 138.4, 135, 122.5, 87.2, 96.5]
x3 = [54.2, 54.9, 54.8, 56.3, 54.5, 54.6, 54.9, 54.8, 49.3, 41.5, 48.9]

relative_rows = list()
relative_rows.append(x0)
relative_rows.append(x1)
relative_rows.append(x2)
relative_rows.append(x3)


class GM:
    def __init__(self, k, n, target_data, relative_data):
        self.k = k
        self.n = n
        self.target_data = target_data
        self.relative_data = relative_data

    def data_process(self):
        target_AGO = self.target_data.copy()
        relative_AGO = self.relative_data.copy()
        for i in range(self.k):
            target_AGO = list(itertools.accumulate(target_AGO))
            for index in range(len(relative_AGO)):
                relative_AGO[index] = list(itertools.accumulate(relative_AGO[index]))
        # print(relative_AGO, '\n', self.relative_data)
        Z = list()
        for index in range(1, len(target_AGO)):
            Z.append((target_AGO[index] + target_AGO[index-1]) / 2)
        B = -np.mat(Z).reshape(-1, 1)
        X = np.array(relative_AGO)[:, 1:].T
        B = np.hstack((B, X))
        Y = np.mat(self.target_data[1:]).T.reshape(-1, 1)
        xi = np.array(relative_AGO)
        self.xi = xi
        self.B = B
        self.X = X
        self.Y = Y

    def generate_model_args(self):
        theat = np.linalg.inv(self.B.T.dot(self.B)).dot(self.B.T).dot(self.Y)
        al = float(theat[:1, :])
        b = np.array(theat[1:, :].T).flatten()
        U = list(b.dot(self.xi))
        b = list(b)
        print("U:", U)
        self.al = al
        self.b = b
        self.U = U

    def predict(self):
        F = list()
        F.append(self.target_data[0])
        for index in range(1, len(self.target_data)):
            F.append((self.target_data[0] - self.U[index - 1] / self.al) / math.exp(self.al * index) + self.U[index - 1] / self.al)
        print("F", F)
        G = list()
        G.append(self.target_data[0])
        for index in range(1, len(self.target_data)):
            G.append(F[index] - F[index - 1])
        print("G:", G)
        self.F = F
        self.G = G

    def show_result(self):
        t = list(range(len(self.target_data)))

        plt.plot(t, a, color='r', linestyle="--", label='true')
        plt.plot(t, self.G, color='b', linestyle="--", label="predict")
        plt.legend(loc='upper right')
        plt.show()


my_model = GM(1, 5, target_data=a, relative_data=relative_rows)
my_model.data_process()
my_model.generate_model_args()
my_model.predict()
my_model.show_result()
```

## 预测模型的普适种类

- 基于原始数据预测
- 基于更新后的数据预测
- 基于滑动窗口预测



